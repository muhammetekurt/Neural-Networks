{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "question_2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "VrrP6yU2uvnz"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.array([[0, 0, 1],\n",
        "               [0, 1, 1],\n",
        "               [1, 0, 1],\n",
        "               [1, 1, 1]])"
      ],
      "metadata": {
        "id": "8GI9qZ4lu3tN"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = np.array([[0],\n",
        "             [1],\n",
        "             [1],\n",
        "             [0]])"
      ],
      "metadata": {
        "id": "HOuF0lWNvTg-"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "alpha = 0.05\n",
        "batch = 60000"
      ],
      "metadata": {
        "id": "VOPbWXQYvVer"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(1)"
      ],
      "metadata": {
        "id": "6tT26l7cvX-U"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# initalize tghe weights randomly \n",
        "\n",
        "w0 = 2*np.random.random((3,4)) -1 \n",
        "w1 = 2*np.random.random((4,1))"
      ],
      "metadata": {
        "id": "NXSFaBXNvZuw"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sj_NsDeMvbtb",
        "outputId": "85c7c4d7-dbff-475c-f91d-4dee016c339d"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.16595599,  0.44064899, -0.99977125, -0.39533485],\n",
              "       [-0.70648822, -0.81532281, -0.62747958, -0.30887855],\n",
              "       [-0.20646505,  0.07763347, -0.16161097,  0.370439  ]])"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#eq #1 \n",
        "\n",
        "def sigmoid(z):\n",
        "  return 1 / (1 + np.exp( -z ))"
      ],
      "metadata": {
        "id": "l4XBbQ4qvd4u"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sigmoid prime eq # 2\n",
        "def sigmoid_prime(z):\n",
        "  return (z * (1 - z))"
      ],
      "metadata": {
        "id": "atbJEdiFvfZ5"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#burada bir mini batch algoritması tanımladım\n",
        "#mini batch gradient descent, training set'in model errorlarını ve ve model ceofficient'larını hesaplamak için kullanılan bir optimization algoritmasıdır.\n",
        "batch_size=2\n",
        "mini_batches = []\n",
        "data = np.hstack((x, y))\n",
        "np.random.shuffle(data)\n",
        "#n_minibatches = data.shape[0] // batch_size\n",
        "i = 0\n",
        "  \n",
        "for i in range(batch_size):\n",
        "  mini_batch = data[i * batch_size:(i + 1)*batch_size, :]\n",
        "  X_mini = mini_batch[:, :-1]\n",
        "  Y_mini = mini_batch[:, -1].reshape((-1, 1))\n",
        "  mini_batches.append((X_mini, Y_mini))"
      ],
      "metadata": {
        "id": "gboWvOYT11yh"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ilk for döngüsünün içine ikinci bir for döngüsü ekledim\n",
        "#bunun sebebi ise, yukarıda yazmış olduğum mini-batch algoritmasının array'ini kullanabilmek.\n",
        "#mini batch algoritmasındaki array'imi bu döngüye koyarak her değer için dolaştırıyorum ve benden istenen değerleri elde etmiş oluyorum.\n",
        "for cntr in range(batch):\n",
        "  for mbatch in mini_batches:\n",
        "    batch_x, batch_y = mbatch\n",
        "    n = batch_x.shape[0]\n",
        "    a0 = batch_x \n",
        "    z1 = np.dot(a0, w0)\n",
        "    a1 = sigmoid(z1)\n",
        "    z2 = np.dot(a1, w1)\n",
        "\n",
        "    # second layer activation function values \n",
        "    a2 = sigmoid(z2)\n",
        "\n",
        "    l2_error = (a2 - batch_y)/n\n",
        "\n",
        "    if cntr % 1000 ==0:\n",
        "      print(\"Error: \", str(np.mean(np.mean(np.abs(l2_error)))))\n",
        "\n",
        "    # eq 6\n",
        "    l2_delta = l2_error * sigmoid_prime(a2)\n",
        "\n",
        "    l1_error = l2_delta.dot(w1.T)\n",
        "\n",
        "    # eq 7 \n",
        "    l1_delta = l1_error * sigmoid_prime(a1)\n",
        "\n",
        "    # eq #  5 \n",
        "    w1 -= alpha*a1.T.dot(l2_delta)\n",
        "    w0 -= alpha*a0.T.dot(l1_delta)"
      ],
      "metadata": {
        "id": "5p5c29zFvg7Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc99d25f-32a4-45d1-a057-3f8edcc3512b"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error:  0.24920560169184325\n",
            "Error:  0.2510545185918266\n",
            "Error:  0.23841176962712507\n",
            "Error:  0.25761647212434235\n",
            "Error:  0.22997552767665957\n",
            "Error:  0.2611956359518171\n",
            "Error:  0.21882057615769107\n",
            "Error:  0.26367659286813516\n",
            "Error:  0.20255554401996145\n",
            "Error:  0.265168981285434\n",
            "Error:  0.1803679648861115\n",
            "Error:  0.2649266413086337\n",
            "Error:  0.1550137212475366\n",
            "Error:  0.26158622642918616\n",
            "Error:  0.13197372067620278\n",
            "Error:  0.25385238256471093\n",
            "Error:  0.11466691631029949\n",
            "Error:  0.24041697618791338\n",
            "Error:  0.10404564516267863\n",
            "Error:  0.21722742314374807\n",
            "Error:  0.09836842240789151\n",
            "Error:  0.17918870432546558\n",
            "Error:  0.08990561052272264\n",
            "Error:  0.1439988171019808\n",
            "Error:  0.07943232849949344\n",
            "Error:  0.11849057315095565\n",
            "Error:  0.06972746735950451\n",
            "Error:  0.10020378974398647\n",
            "Error:  0.061657321091369593\n",
            "Error:  0.0867944865891477\n",
            "Error:  0.055149054305742115\n",
            "Error:  0.0766828743137756\n",
            "Error:  0.04990461523927081\n",
            "Error:  0.06884731485441467\n",
            "Error:  0.045635580693540415\n",
            "Error:  0.06262374926569397\n",
            "Error:  0.04211319289246081\n",
            "Error:  0.057572189660011944\n",
            "Error:  0.039166085641554806\n",
            "Error:  0.0533940676537083\n",
            "Error:  0.03666760221343988\n",
            "Error:  0.0498817071721033\n",
            "Error:  0.03452382124564525\n",
            "Error:  0.046887169435705936\n",
            "Error:  0.032664386566631495\n",
            "Error:  0.04430270322363961\n",
            "Error:  0.031035918082526242\n",
            "Error:  0.042048215673381364\n",
            "Error:  0.02959736714828654\n",
            "Error:  0.04006306324595563\n",
            "Error:  0.02831674675484985\n",
            "Error:  0.03830055517278579\n",
            "Error:  0.027168814058209395\n",
            "Error:  0.03672419608719975\n",
            "Error:  0.026133410767401413\n",
            "Error:  0.035305067135130055\n",
            "Error:  0.025194260417220955\n",
            "Error:  0.03401996731992332\n",
            "Error:  0.024338085903855777\n",
            "Error:  0.03285007214527101\n",
            "Error:  0.02355395401305612\n",
            "Error:  0.03177995051339444\n",
            "Error:  0.02283278273596058\n",
            "Error:  0.030796833847495503\n",
            "Error:  0.02216696671962594\n",
            "Error:  0.029890065527087575\n",
            "Error:  0.021550089449538373\n",
            "Error:  0.02905068107400193\n",
            "Error:  0.02097669982696259\n",
            "Error:  0.028271084411776008\n",
            "Error:  0.020442137072072368\n",
            "Error:  0.027544795591596408\n",
            "Error:  0.019942392265201486\n",
            "Error:  0.02686625229255926\n",
            "Error:  0.01947399793476167\n",
            "Error:  0.02623065221805452\n",
            "Error:  0.019033939311968923\n",
            "Error:  0.025633826905659882\n",
            "Error:  0.018619582468779202\n",
            "Error:  0.02507213989247738\n",
            "Error:  0.018228615719155728\n",
            "Error:  0.024542403929094393\n",
            "Error:  0.01785900152039714\n",
            "Error:  0.024041813214009847\n",
            "Error:  0.017508936747597285\n",
            "Error:  0.023567887563528084\n",
            "Error:  0.017176819691194337\n",
            "Error:  0.02311842613452739\n",
            "Error:  0.016861222487947154\n",
            "Error:  0.022691468845354855\n",
            "Error:  0.016560867970189554\n",
            "Error:  0.022285264040183272\n",
            "Error:  0.016274610128908334\n",
            "Error:  0.02189824124785559\n",
            "Error:  0.016001417549073832\n",
            "Error:  0.021528988121620227\n",
            "Error:  0.01574035930243872\n",
            "Error:  0.021176230828696643\n",
            "Error:  0.015490592882359804\n",
            "Error:  0.020838817301161716\n",
            "Error:  0.015251353843522657\n",
            "Error:  0.02051570287169069\n",
            "Error:  0.0150219468715613\n",
            "Error:  0.020205937906298592\n",
            "Error:  0.014801738057118477\n",
            "Error:  0.019908657116735277\n",
            "Error:  0.014590148188629222\n",
            "Error:  0.01962307029158957\n",
            "Error:  0.014386646910135494\n",
            "Error:  0.019348454230535314\n",
            "Error:  0.014190747616406936\n",
            "Error:  0.01908414570283258\n",
            "Error:  0.014002002978759531\n",
            "Error:  0.018829535281007087\n",
            "Error:  0.013820001012239683\n",
            "Error:  0.018584061924959056\n",
            "Error:  0.013644361609038721\n",
            "Error:  0.01834720821170264\n",
            "Error:  0.013474733474695081\n",
            "Error:  0.018118496122368415\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"after training:\\n\")\n",
        "print(a2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-mWyVteExPAO",
        "outputId": "5384af1d-30a2-494f-d2e1-a402e3702df9"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "after training:\n",
            "\n",
            "[[0.97014657]\n",
            " [0.04173737]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Bu kod parçacığı aslında q-1 için kullanıldı ancak soruda bizden bu değerleri tekrar train etmemiz istendiği için tekrar bu kod parçacağını kullandık.\n",
        "#çıktların değişmesinin sebebi neural network'ümüzü farklı bir şekilde train etmemizden kaynaklanmaktadır.\n",
        "\n",
        "x1 = [1,1,0]\n",
        "x2 = [1,1,1]\n",
        "\n",
        "def testNN(myTester):\n",
        "\n",
        "  a0 = myTester \n",
        "  z1 = np.dot(a0, w0)\n",
        "  a1 = sigmoid(z1)\n",
        "  z2 = np.dot(a1, w1)\n",
        "  a2 = sigmoid(z2)\n",
        "\n",
        "  return a2\n",
        "\n",
        "#bizden istenilen testNN fonksiyonunu oluşturduk\n",
        "#fonksiyon bir adet parametre alıyor, o parametre değeri bize verilen x1 ve x2 değerlerini test etmek için kullanılıyor.\n",
        "\n",
        "myTest1 = testNN(x1)\n",
        "myTest2 = testNN(x2)\n",
        "\n",
        "print(\"x1 -> y1:\", myTest1)\n",
        "print(\"-------------------\\n\")\n",
        "print(\"x2 -> y2:\", myTest2)\n",
        "\n",
        "#burada ise x1 ve x2 değerlerini testNN fonksiyonuna yolluyorum, return değeri bana elde etmek istediğim sonucu veriyor ve ekrana print ediyorum.\n",
        "\n",
        "\n",
        "print(\"-------------------\\n\")\n",
        "\n",
        "print(\"after training:\\n\")\n",
        "print(a2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AIKA1fBnyIjt",
        "outputId": "3ee2dbc9-cb6e-4a45-d4d9-0013ea01eb87"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x1 -> y1: [0.11968302]\n",
            "-------------------\n",
            "\n",
            "x2 -> y2: [0.04173604]\n",
            "-------------------\n",
            "\n",
            "after training:\n",
            "\n",
            "[[0.97014657]\n",
            " [0.04173737]]\n"
          ]
        }
      ]
    }
  ]
}